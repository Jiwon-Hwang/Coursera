{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Using Real-world Images.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPqAUtEoYCllgciuoInYk/T"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ZXm9wgqsZ2vZ"},"source":["## A conversation with Andrew Ng\r\n","이전 CNN에 적용한 데이터셋보다 훨씬 더 크고 복잡한 실세계의 이미지에 적용하는 방법"]},{"cell_type":"markdown","metadata":{"id":"Lx58h8AWkeX3"},"source":["## Understanding ImageGenerator\r\n","* tensorflow의 **image generator** : 한 directory를 지정하면 하위 이미지들에 자동 label을 지정해줌\r\n","> * cf. target_size를 지정함으로써 수천 개의 이미지를 전처리할 필요가 없다! (load 와 동시에 resize 하므로)   \r\n","> * for 문을 굳이 사용하지 않고 처리 가능.  \r\n","   \r\n"," \"This is coded to read images from subdirectories, and automatically label them from the name of that subdirectory.\"\r\n"]},{"cell_type":"code","metadata":{"id":"88Mt7b2bZvVs"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n","\r\n","train_datagen = ImageDataGenerator(rescale=1./255) # Image Generator 객체 생성, normalize (0~1으로)\r\n","\r\n","train_generator = train_datagen.flow_from_directory(\r\n","    train_dir,\r\n","    target_size = (300, 300), # 신경망 학습 시 모두 동일한 크기여야 하므로 이미지 로드 시 조정!\r\n","    batch_size = 128, # 하나하나 학습하는 것보다 배치 단위로 불러와서 학습하는 게 더 효율적\r\n","    class_mode = 'binary' # 말, 인간 2가지 이진 분류 모드\r\n",")\r\n","\r\n","validation_generator = test_datagen.flow_from_directory(\r\n","    validation_dir,\r\n","    target_size = (300, 300), \r\n","    batch_size = 32, \r\n","    class_mode = 'binary'\r\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DcAPQMn843Ih"},"source":["## Defining a ConvNet to use complex images\r\n","* input_shape : (300, 300, 3) **3채널 컬러 이미지**\r\n","* output layer : **노드 1개**\r\n","> ***이전에는 각 클래스당 1개식 총 10개의 뉴런이엇지만, 지금은 두 클래스에 대해 1개의 뉴런만!***  \r\n","* cf. **sigmoid** 활성화 함수 : **이진 분류 (0, 1)**에 적합\r\n","* cf. **softmax** 활성화 함수 : 큰 값은 더 크게 활성, 작은 값은 더 작게 억제"]},{"cell_type":"code","metadata":{"id":"al_dfWBc47o5"},"source":["model = tf.keras.models.Sequential([\r\n","    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(300, 300, 3)), # ret : (298, 298)\r\n","    tf.keras.layers.MaxPooling2D(2, 2),\r\n","    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\r\n","    tf.keras.layers.MaxPooling2D(2, 2),\r\n","    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'), # 64개의 마스크 제공 -> ret : (71, 71)\r\n","    tf.keras.layers.MaxPooling(2, 2), # ret : (35, 35) 크기의 이미지, 64개의 컨볼루션(커널, 마스크, 가중치)\r\n","\r\n","    tf.keras.layers.Flatten(), # (35, 35, 64) -> (78400)\r\n","    tf.keras.layers.Dense(512, activation='relu'),\r\n","    tf.keras.layers.Dense(1, activation='sigmoid') # 2개의 클래스지만 1개의 출력 노드! (sigmoid)                                      \r\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vCctRvKGITHy"},"source":["#### cf. Output Shape"]},{"cell_type":"markdown","metadata":{"id":"RY_JDfbN_yr5"},"source":["* 16, 32, 64... : 커널(컨볼루션 마스크) 개수!\r\n","* 35 x 35 x 64 = 78400 : 총 가중치(w) 개수 \r\n","> \"CNN : **최적의 커널(컨볼루션 마스크 = 가중치)을 자동으로 찾아준다!**\""]},{"cell_type":"markdown","metadata":{"id":"AqpcFiemN-gE"},"source":["## Training the Convnet with fit_generator\r\n","model.fit 대신 model.fit_generator\r\n","* RMSprop (optimizer) : 학습 속도를 조정하여 성능 평가 가능"]},{"cell_type":"code","metadata":{"id":"_wf18d14ORe7"},"source":["from tensorflow.keras.optimizers import RMSprop\r\n","\r\n","# compile : 모델 학습 과정 정의\r\n","model.compile(loss='binary_crossentropy', # 이전 loss : categorical cross entropy\r\n","              optimizer=RMSprop(lr=0.001), # 이전 optimizer : Adam\r\n","              metrics=['acc'])\r\n","\r\n","# fit_generator : 모델 학습\r\n","history = model.fit_generator(\r\n","    train_generator, # 학습데이터 dir에서 이미지들 불러옴\r\n","    steps_per_epoch = 8, # 학습데이터 모두를 로드하려면 batch_size=128 * 8 steps 배치를 수행해야 함!\r\n","    epochs = 15, # 학습 epoch 수\r\n","\r\n","    validation_data = validation_generator,\r\n","    validation_steps = 8, # batch_size=32 * 8 steps 배치를 수행해야 전체 256개의 val_data 로드\r\n","    verbose = 2 # 훈련이 진행되는 동안 표시 할 양 지정 (화살표 2개씩 진행상황 보여줌 * 8 steps)\r\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tR77RvEvb4QT"},"source":["== == == == == == == ==> : 이렇게 == 2개씩 훈련과정 표시하고, 한 == 당 32개의 이미지 데이터들 처리, 총 8 step으로 전체 256개 데이터 다 학습. 이 전체 과정을 총 15 epochs 만큼 반복!"]},{"cell_type":"code","metadata":{"id":"ARtTulp1VBz0"},"source":["# 훈련을 마친 모델으로 예측\r\n","import numpy as np\r\n","from google.colab import files # 불러오기 버튼 창 제공\r\n","from keras.preprocessing import image\r\n","\r\n","uploaded = files.upload() # 불러오기 (이미지 경로들이 uploaded 에 불러와짐)\r\n","#print(type(uploaded)) : dict?\r\n","\r\n","for fn in uploaded.keys():\r\n","\r\n","  #predicting images\r\n","  path = '/content/' + fn\r\n","  img = image.load_img(path, target_size=(300, 300)) # 위에서 설계한 모델의 input size와 일치하도록 load!\r\n","  x = image.img_to_array(img)\r\n","  x = np.expand_dims(x, axis = 0)\r\n","\r\n","  images = np.vstack([x])\r\n","  classes = model.predict(images, batch_size=10) # 클래스 배열 반환 : 한 클래스당 한 item(0 or 1에 가까운 값)\r\n","  print(classes[0]) # only one value!\r\n","  if classes[0] > 0.5:\r\n","    print(fn + \" is a human\") # 1에 가까우면 사람\r\n","  else:\r\n","    print(fn + \" is a horse\") # 0에 가까우면 말"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VbBl4jQzXxE3"},"source":["## Walking through training the ConvNet with fit_generator\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"i6lklnOOhsS7"},"source":["## Adding automatic validation to test accuracy\r\n","validation set : 신경망이 이전에 보지 못했던 새로운 데이터이므로, train_acc > val_acc"]},{"cell_type":"markdown","metadata":{"id":"3J_7C_pg1jgi"},"source":["## Exploring the impact of compressing images\r\n","첫번째 Conv2D층의 input shape를 (300, 300) -> (150, 150)으로 줄이면? (데이터 양을 1/4로 축소)\r\n","> * **학습 속도**가 빨라짐\r\n","* **acc**는 1.000이 나오지만 **val_acc**는 그렇지 않은 값이 나오는 등 **과적합(over-fitting)**이 일어남\r\n","* 또한, 작은 크기의 이미지를 다루기 위해 컨볼루션 몇 개를 제거했기 때문에 다른 결과가 도출됨\r\n","  \r\n","따라서 나중에 test 시 잘못 분류하는 오류가 생김!\r\n","  \r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"zN8sQ7Fc38o2"},"source":["#### [importance of validation set]\r\n","어디에서 오류가 났는지, 어떤 data를 어떻게 수정해야 좋은 학습 결과를 도출해내는지 알 수 있음\r\n","> \"**validation set**이란, training을 한 후에 만들어진 모형이 잘 예측을 하는지 그 성능을 평가하기 위해서 사용한다. training set의 일부를 모델의 성능을 평가하기 위해서 희생하는 것\""]}]}