{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Exercise 2 (Handwriting Recognition).ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMS4md8lAR/apGLJKJ+s/rl"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Is88izG0MyzV"},"source":["## Exercise 2\r\n","In the course you learned how to do classificaiton using Fashion MNIST, a data set containing items of clothing. There's another, similar dataset called MNIST which has items of handwriting -- the digits 0 through 9.\r\n","\r\n","Write an MNIST classifier that trains to 99% accuracy or above, and does it without a fixed number of epochs -- i.e. you should stop training once you reach that level of accuracy.\r\n","\r\n","Some notes:\r\n","1. It should succeed in less than 10 epochs, so it is okay to change epochs= to 10, but nothing larger\r\n","2. When it reaches 99% or greater it should print out the string \"Reached 99% accuracy so cancelling training!\"\r\n","3. If you add any additional variables, make sure you use the same names as the ones used in the class\r\n","\r\n","I've started the code for you below -- how would you finish it? "]},{"cell_type":"markdown","metadata":{"id":"2OuNGXIb5ydi"},"source":["## My code\r\n","logs에서 acc 대신 loss 값 가져오기\r\n","```py\r\n","def on_epoch_end(self, epoch, logs={}):\r\n","    if(logs.get('loss')<0.02): # 'loss'!\r\n","      print(\"\\nReached 99% accuracy so cancelling training!\")\r\n","      self.model.stop_training = True\r\n","```"]},{"cell_type":"code","metadata":{"id":"v8Fzum31MsNM","executionInfo":{"status":"ok","timestamp":1611740202925,"user_tz":-540,"elapsed":729,"user":{"displayName":"황지원","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj3QkHCcEEvrl0G2GezbnmqYv8hfEf2EXH8W_8vNw=s64","userId":"04698757380061261060"}}},"source":["import tensorflow as tf\r\n","from os import path, getcwd, chdir\r\n","\r\n","# DO NOT CHANGE THE LINE BELOW. If you are developing in a local\r\n","# environment, then grab mnist.npz from the Coursera Jupyter Notebook\r\n","# and place it inside a local folder and edit the path to that location\r\n","path = f\"{getcwd()}/../tmp2/mnist.npz\""],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"xuVkGjibMtjZ"},"source":["# GRADED FUNCTION: train_mnist\r\n","def train_mnist():\r\n","    # Please write your code only where you are indicated.\r\n","    # please do not remove # model fitting inline comments.\r\n","\r\n","    # YOUR CODE SHOULD START HERE\r\n","    class myCallback(tf.keras.callbacks.Callback):\r\n","        def on_epoch_end(self, epoch, logs={}):\r\n","            if(logs.get('loss')<0.02):\r\n","                print(\"\\nReached 99% accuracy so cancelling training!\")\r\n","                self.model.stop_training = True\r\n","                \r\n","    callbacks = myCallback()\r\n","    # YOUR CODE SHOULD END HERE\r\n","\r\n","    mnist = tf.keras.datasets.mnist\r\n","\r\n","    (x_train, y_train),(x_test, y_test) = mnist.load_data(path=path)\r\n","    # YOUR CODE SHOULD START HERE\r\n","    x_train = x_train / 255.0\r\n","    x_test = x_test / 255.0\r\n","    # YOUR CODE SHOULD END HERE\r\n","    model = tf.keras.models.Sequential([\r\n","        # YOUR CODE SHOULD START HERE\r\n","        tf.keras.layers.Flatten(),\r\n","        tf.keras.layers.Dense(128, activation=tf.nn.relu), # Q. 128? 512???\r\n","        tf.keras.layers.Dense(10, activation=tf.nn.softmax)\r\n","        # YOUR CODE SHOULD END HERE\r\n","    ])\r\n","\r\n","    model.compile(optimizer='adam',\r\n","                  loss='sparse_categorical_crossentropy',\r\n","                  metrics=['accuracy'])\r\n","    \r\n","    # model fitting\r\n","    history = model.fit(# YOUR CODE SHOULD START HERE\r\n","        x_train, y_train, epochs=10, callbacks=[callbacks]\r\n","              # YOUR CODE SHOULD END HERE\r\n","    )\r\n","    # model fitting\r\n","    return history.epoch, history.history['acc'][-1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fcbUHLtrPSw-"},"source":["train_mnist()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CsshvDBh528o"},"source":["## Answer code\r\n","logs에서 loss 대신 acc 값 가져오기\r\n","```py\r\n","def on_epoch_end(self, epoch, logs={}):\r\n","    if(logs.get('accuracy')>0.99): # 'accuracy'!\r\n","      print(\"\\nReached 99% accuracy so cancelling training!\")\r\n","      self.model.stop_training = True\r\n","```"]},{"cell_type":"code","metadata":{"id":"LiepzWck55bA"},"source":["class myCallback(tf.keras.callbacks.Callback):\r\n","  def on_epoch_end(self, epoch, logs={}):\r\n","    if(logs.get('accuracy')>0.99):\r\n","      print(\"\\nReached 99% accuracy so cancelling training!\")\r\n","      self.model.stop_training = True\r\n","\r\n","mnist = tf.keras.datasets.mnist\r\n","\r\n","(x_train, y_train),(x_test, y_test) = mnist.load_data()\r\n","x_train, x_test = x_train / 255.0, x_test / 255.0\r\n","\r\n","callbacks = myCallback()\r\n","\r\n","model = tf.keras.models.Sequential([\r\n","  tf.keras.layers.Flatten(input_shape=(28, 28)),\r\n","  tf.keras.layers.Dense(512, activation=tf.nn.relu),\r\n","  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\r\n","])\r\n","model.compile(optimizer='adam',\r\n","              loss='sparse_categorical_crossentropy',\r\n","              metrics=['accuracy'])\r\n","\r\n","model.fit(x_train, y_train, epochs=10, callbacks=[callbacks])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H96h5IN_85Vw"},"source":["<hr>"]},{"cell_type":"markdown","metadata":{"id":"toa8PwAQ9GNh"},"source":["## cf. loss vs accuracy?\r\n","* **loss** : 훈련 손실값(**오차**)\r\n","> * 0에 수렴하고 작을수록 좋은 모델\r\n","> * **continuous variable (difference between values)**\r\n","  \r\n","* **accuracy** : 훈련 **정답률**\r\n","> * 1에 가깝고 높을수록 좋은 모델\r\n","> * **discrete variable (correct ratio for sample)**\r\n","  > * 즉, 각 샘플에 대해 맞으면 1, 틀리면 0을 매기고 그것들의 총 평균을 구하는 것!\r\n","    \r\n","      \r\n","![](https://kharshit.github.io/img/lossVsAccuracy.png)"]},{"cell_type":"markdown","metadata":{"id":"zJO8X_wRFq5L"},"source":["## cf. metrics = ['accuracy']?\r\n","metrics : 훈련을 모니터링(평가)하기 위한 지표"]},{"cell_type":"markdown","metadata":{"id":"PpVFxFBf9ETY"},"source":["## cf. x_train과 x_test 이미지를 255로 나누는 이유?\r\n","for **normalization!** (0 ~ 255 -> 0 ~ 1 사이 값으로 정규화 하여 다루기)  \r\n","  \r\n","> * train, test 이미지는 numpy array이므로 /255로 간단히 정규화 할 수 있다! \r\n","> * 단, 정규화를 하지 않았을 때보다 했을 경우 loss가 좀 더 작게 나온다"]},{"cell_type":"markdown","metadata":{"id":"iIMSKiSgCvBL"},"source":["## cf. Dense layer의 뉴런(노드) 수를 늘리면?\r\n","Dense(128, ...) -> 512, 1024로 늘리면,\r\n","* 훈련시간은 길어지고\r\n","* 정확도(accuracy)는 올라간다!\r\n","\r\n","> 하지만 항상 비례하는 것은 X!\r\n"]}]}