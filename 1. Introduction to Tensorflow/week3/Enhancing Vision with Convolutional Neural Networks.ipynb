{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Enhancing Vision with Convolutional Neural Networks.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOa00irJIFPUJ9qCk/MFV6o"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"yaAakkwIwMPb"},"source":["## A conversation with Andrew Ng\r\n","* Convolution Neural Network : 모든 픽셀을 보는 대신, 특정 특징 픽셀 값들만 보고 학습 및 예측하는 모델\r\n","* Convolution : 필터 연산 for 특징 추출"]},{"cell_type":"markdown","metadata":{"id":"boylLQtr2OXe"},"source":["## What are convolutions and pooling?\r\n","#### [Convolution]\r\n","* 이미지에는 28 x 28 = 784 픽셀이라는 큰 공간이 허비되고 있음\r\n","* 따라서 **컨볼루션 연산**을 통해서 이미지를 압축시켜야 함 (***filtering***)\r\n","> 이게 바로 **특징 추출, 특징 강조** (ex. edge detection)\r\n","  \r\n","#### [pooling]\r\n","* 쉬운 정보 관리를 위해, 단순히 이미지를 **압축**하는 방법 (***compressing***)\r\n","* 특정 영역 내에서 max 값 등에 해당하는 픽셀만 취하는 방식"]},{"cell_type":"markdown","metadata":{"id":"oq4d16gv3_3m"},"source":["## Implementing convolutional layers\r\n","* 64 : generate 64 filters (known good filters)\r\n","* (3, 3) : 3 x 3 filter size\r\n","* relu : negative values will be thrown away\r\n","  \r\n","> 첫 conv2d의 outputshape인 (26, 26, 64) : 28 x 28 에서 양 끝 픽셀 1개씩 줄어든 26 x 26 & 64개의 filters"]},{"cell_type":"code","metadata":{"id":"dKj-o56muWro"},"source":["model = tf.keras.models.Sequential([\r\n","  tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape(28, 28, 1)),\r\n","  tf.keras.layers.MaxPooling2D(2, 2),\r\n","  tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\r\n","  tf.keras.layers.MaxPooling2D(2, 2),\r\n","\r\n","  tf.keras.layers.Flatten(),\r\n","  tf.keras.layers.Dense(128, activation=tf.nn.relu),\r\n","  tf.keras.layers.Dense(10, activation=tf.nn.softmax),                                    \r\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ywJABGsBAoF8"},"source":["## Implementing pooling layers\r\n","* (2, 2) : 2 x 2 영역(pool)에서 max값 구하기"]},{"cell_type":"code","metadata":{"id":"Xx4fwnNSAs4S"},"source":["model = tf.keras.models.Sequential([\r\n","  tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape(28, 28, 1)), # (26, 26, 64)\r\n","  tf.keras.layers.MaxPooling2D(2, 2), # (13, 13, 64)\r\n","  tf.keras.layers.Conv2D(64, (3, 3), activation='relu'), # (11, 11, 64)\r\n","  tf.keras.layers.MaxPooling2D(2, 2), # (5, 5, 64) : 5 x 5 크기의 이미지 64장이 다음 층으로 들어감!\r\n","\r\n","  tf.keras.layers.Flatten(), # 1600개의 노드 (5 x 5 x 64 = 1600 x 1)\r\n","  tf.keras.layers.Dense(128, activation=tf.nn.relu),\r\n","  tf.keras.layers.Dense(10, activation=tf.nn.softmax),                                    \r\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HgaUy3DTW8QC"},"source":["model.summary() # 모델의 레이어들 검사, 각 층의 shape 출력"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O4j__fLtaEbH"},"source":["따라서, Convolution과 Pooling 층이 없었다면, 1600개보다 훨씬 큰 데이터들을 가지고 학습했어야 함!\r\n","> CNN의 목적 (By. 정보 압축, 이미지 인식 성능 향상)"]},{"cell_type":"markdown","metadata":{"id":"HD_Xh1u-ZLRg"},"source":["## Improving the Fashion classifier with convolutions"]},{"cell_type":"markdown","metadata":{"id":"ghzI6Sbmevw_"},"source":["## Walking through convolutions\r\n","* 컨볼루션 후 : 수평 or 수직선 등 특징 추출 (강조)\r\n","* 풀링 후 : 위의 결과 이미지의 기능 유지 & 크기 축소  \r\n","  \r\n","  > 이 때, tensorflow는 입력 이미지에 여러가지 filters(ex. 64가지)를 적용하하면서 어떤 필터가 잘 작동하는지 (원하는 결과를 잘 도출하는지) 학습한다!"]}]}