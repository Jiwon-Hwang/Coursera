{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Augmentation: A technique to avoid overfitting.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN56cavBdsDzpwc/n2CoqGg"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"l4SskQNGeh7C"},"source":["## A conversation with Andrew Ng\r\n","* Augmentation을 위한 tensorflow의 쉬운 툴들 소개\r\n","* For avoiding overfitting\r\n","* Augmentation : 모델 학습 도중에 그때그때 이미지를 변형시킴\r\n","> * 직접 원본 이미지를 수정하는 것 X (not on-disk)\r\n","> * 메모리 상에서만 학습 시에 수행 O (in-memory)"]},{"cell_type":"markdown","metadata":{"id":"CvgCE582rZe1"},"source":["## Introducing augmentation\r\n","* 제한된(적은) 데이터로 학습 시, overfitting이 일어나며 분류를 잘 못하게 됨\r\n","* 무한한 크기의 데이터로 완벽한 분류기를 만든다고 하면, 학습 시간이 매우 오래 걸릴 것\r\n","* 따라서 Augmentation 필요!"]},{"cell_type":"markdown","metadata":{"id":"2OteuKrwsrw6"},"source":["## Coding augmentation with ImageDataGenerator"]},{"cell_type":"code","metadata":{"id":"45a0pBS8duBN"},"source":["# 이전 방식 (little augmentation)\r\n","train_datagen = ImageDataGenerator(rescale=1./255) # 이것부터가 little image augmentation (rescale)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u_xfT1VKuIjC"},"source":["# Updated to do image augmentation\r\n","train_datagen = ImageDataGenerator(\r\n","    rescale=1./255,\r\n","    rotation_range=40,\r\n","    width_shift_range=0.4, # randomly move (proportion of the image), up to 40% of the image\r\n","    height_shift_range=0.2,\r\n","    shear_range=0.2,\r\n","    zoom_range=0.2,\r\n","    horizontal_flip=True, # 무작위 좌우반전\r\n","    fill_mode='nearest' # 위 작업에 의해 손실된 픽셀들을 채움 (uses neighbors)\r\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z6GJ7-8QTZ9q"},"source":["## Demonstrating overfitting in cats vs. dogs\r\n","ImageDataGenerator에 각종 augmentation 설정 후에 overfitting이 일어나지 않음! (val_acc도 잘 올라가고, val_loss도 잘 떨어짐)"]},{"cell_type":"markdown","metadata":{"id":"KLCIxhBbT0sv"},"source":["## Adding augmentation to cats vs. dogs\r\n","Data Augmentation 추가의 효과\r\n","* 처음엔 aug 하지 않았을 때보다 aug 했을 때 더 낮은 초기 acc\r\n","> random effect 때문!\r\n","* 점점 제자리(추세)를 잘 찾아감"]},{"cell_type":"markdown","metadata":{"id":"fDuf8cvXVH38"},"source":["## Exploring augmentation with horses vs. humans\r\n","* augmentation이 overfitting을 해결하는 만능 열쇠는 X!\r\n","> 이미지 다양성이 아직도 적을 수도 있음... **(여전히 train과 val이 비슷할 수 있음..!)**\r\n","* augmentation을 수행하면 **학습 데이터(train set)가 변형**되고, **검증 데이터(validation set)은 원래와 같으므로** 다른 두 모습으로 평가 가능!\r\n","* augmentation 후, training acc는 안정적으로 올라가지만 validation acc는 미친듯이 왔다갔다 함\r\n","> **image augmentation이 training set에만 random element를 적용하는 것이기 때문!** (validation set에는 같은 random 적용 X)"]}]}