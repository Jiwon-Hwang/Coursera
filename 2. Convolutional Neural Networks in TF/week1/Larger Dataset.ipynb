{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Larger Dataset.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNMX744EQz1V6R1WM/oiV/T"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"6R8mdqXxU5hV"},"source":["## Introduction, A conversation with Andrew Ng\r\n","* 큰 데이터셋 사용 시 over-fitting 위험이 조금 줄어듦\r\n","* Data augmentation 방법으로도 over-fitting 방지 가능\r\n","* Multicast learning (more than two classes)"]},{"cell_type":"markdown","metadata":{"id":"-BhBL3l1W8qx"},"source":["## A conversation with Andrew Ng\r\n","더러운 데이터 (ex. 길이가 0인 데이터, 고양이를 들고 있는 사람 등) --> Tensorflow로 처리 가능!"]},{"cell_type":"markdown","metadata":{"id":"iKhu1gtMdTKE"},"source":["## Training with the cats vs. dogs dataset"]},{"cell_type":"code","metadata":{"id":"l38H9rHGUm2J"},"source":["# ImageDataGenerator : auto labeling subdirectories' dataset\r\n","\r\n","from tensorflow.keras.preprocessing.image\r\n","import ImageDataGenerator\r\n","\r\n","# create instance, normalization\r\n","train_datagen = ImageDataGenerator(rescale=1./255) \r\n","\r\n","train_generator = train_datagen.flow_from_directory(train_dir, \r\n","                                                    target_size=(150, 150),\r\n","                                                    batch_size=20, \r\n","                                                    class_mode='binary')\r\n","\r\n","validation_generator = test_datagen.flow_from_directory(\r\n","    validation_dir,\r\n","    target_size=(150, 150),\r\n","    batch_size=20,\r\n","    class_mode='binary'\r\n",")\r\n","\r\n","\r\n","# create model\r\n","model = tf.keras.model.Sequential([\r\n","    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)), # ret_size:(148, 148)\r\n","    tf.keras.layers.MaxPooling2D(2, 2), # (74, 74)\r\n","    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'), # (72, 72)\r\n","    tf.keras.layers.MaxPooling2D(2, 2), # (36, 36)\r\n","    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'), # (34, 34)\r\n","    tf.keras.layers.MaxPooling2D(2, 2), # (17, 17)\r\n","    tf.keras.layers.Flatten(), # 18496 == 17 * 17 * 64\r\n","    tf.keras.layers.Dense(512, activation='relu'), # 512\r\n","    tf.keras.layers.Dense(1, activation='sigmoid') # 1\r\n","])\r\n","\r\n","\r\n","# compile model\r\n","from tensorflow.keras.optimizers import RMSprop\r\n","\r\n","model.compile(loss='binary_crossentropy',\r\n","              optimizer=RMSprop(lr=0.001), # RMSprop automates learning-rate tuning (lr)\r\n","              metrics=['acc'])\r\n","\r\n","# train model\r\n","history = model.fit_generator(\r\n","    train_generator, \r\n","    steps_for_epoch=100, # batch_size=20 * 100회 후에야 전체 학습 데이터 2000장 로드 완료\r\n","    epochs=15,\r\n","    validation_data=validation_generator,\r\n","    validation_steps=50, # batch_size=20 * 50회 후에야 전체 검증 데이터 1000장 로드 완료\r\n","    verbose=2\r\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pwDEXkLImbyU"},"source":["## Fixing through cropping\r\n","위의 방식처럼 학습을 진행하면 한두장 잘못 분류하는 경우가 생김 ==> 해결책? \r\n","> cropping! (고양이 사진에서 헷갈리게 만들만한 영역을 자른다)"]},{"cell_type":"markdown","metadata":{"id":"pDOvsCEuv2Gn"},"source":["## Visualizing the effect of the convolutions\r\n","* 컨볼루션 신경망이 이미지의 어떤 특징을 중점으로 학습하게 되는지 visualize!\r\n","> ex. 강아지의 귀, 개구리의 눈 등\r\n","* model.layers (API) : allows to find the outputs and iterate through them, creating a visualization model for each one\r\n","> ```py\r\n","successive_outputs = [layer.output for layer in model.layers[1:]]\r\n","visualization_model = Model(img_input, successive_outputs)\r\n","```"]},{"cell_type":"markdown","metadata":{"id":"SVzOAMVoyb6-"},"source":["## Looking at accuracy and loss\r\n","* cf. history = model.fit_generator() == model.fit()\r\n","* 데이터 수가 적으면 **overfitting** 일어남\r\n","> **overfitting** : train_acc는 점점 100%에 가까워지는데, val_acc는 70%까지만 초기에 오르고 더 이상 오르지 않음!"]}]}